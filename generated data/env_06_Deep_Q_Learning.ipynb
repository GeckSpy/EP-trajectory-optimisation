{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating gymnasium environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to adapt this notebook to your environment ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "DQN :\n",
    "- The input size of the nn depends on the size of the input state : adapt the size of the first layer \n",
    "\n",
    "Env: \n",
    "- Don't modify :\n",
    "    - policy \n",
    "    - random_action \n",
    "\n",
    "- Modify :\n",
    "    - init :\n",
    "        - n_action : we assume the action space to be finite, and we hope small \n",
    "        - done : this attribute say if the episode is finished, it needs to be set to true when we do the reset, and we need to update in the function step\n",
    "        - every attribute you need to build the function step, state, show_state\n",
    "    - state : must return a batch of size 1 : \n",
    "        - typically our state is a vector of size say d, so a tensor of size (d). Here we want the function \n",
    "            to return a batch of size one , so we return a vector of size (1,d) e.g [t] where t is our size \n",
    "    - show_state \n",
    "    - reset : must update the attribute done, and your internal attribute that give the current state of the episode\n",
    "    - step : take an action as a tensor (we access it by action.item() ) and returns a namedtuple Transition \n",
    "    with 4 coordinates (state,action,next_state,reward) \n",
    "            - every reward must be in [0,1] to make easier the hyperparameter finetuning\n",
    "            - state and next_state must be a batch of size one (as for the function state)\n",
    "            - action should be a batch of size one\n",
    "            - if the episode is finished after the action, next_state must be None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environment is:\n",
    " - A $N \\times M$ grid of cases with $N,M \\in \\mathbb{N}$ supposed to be a loop track.\n",
    " - Each case is in $\\{0,1,3,4\\}$ such that:\n",
    "   - $0 \\rightarrow$ road (white)\n",
    "   - $1 \\rightarrow$ wall (black)\n",
    "   - $STAR\\_ CHAR$ (3) $\\rightarrow$ starting point\n",
    "\n",
    " - A Car that follow some model for trajectory. The car can do the next action:\n",
    "   - accelerate (add $1$ to car speed)\n",
    "   - brake (divide the car speed by $1.5$)\n",
    "   - turn (need to specify the angle)\n",
    "   - do nothing\n",
    "  \n",
    " - Possible Actions $(a,b) \\in \\{-1,0,1\\} \\times [-K,K]$ where:\n",
    "   - $a=1$ for acceleration, $-1$ for brake and $0$ for nothing\n",
    "   - $b>0$ for turning left with angle, $b<0$ to turn right and 0 for nothing. Note that a turn, in this environment is always in $[-K,K]$ where $K$ is the value of `env.max_turn` variable.\n",
    "\n",
    " - The state is a $8$ vector $V$\n",
    "   - $V[0]$ is the speed of the car $\\geq 0$\n",
    "   - $V[i]$ (for $i \\in [8]$) is the distance to the wall with rotation $90 - 30i$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "To create your turn/your track, use the grid notation (for better visualisation) like env_01 and env_02. The grid is used with the matrix notation. If we denote the grid by $G$, then $G[0][0]$ is the top left case, $G[x][y]$ is the case on the $x$-th row (from top to bottom) and on the $y$-th column (from left to right).\n",
    "\n",
    "You can also use image for that with balck pixel for wall, white for starting point, any other color will be interpreted as road.\n",
    "\n",
    "Nevertheless, for all the other things, we use axis coordinates, i.e., $G[x][y]$ refer to the case situate at coordinate $(x,y)$. More preciselly, it is the case on the $x$-th column (from left to right) and on the $y$-th row (from bottom to top). Therefore you can simply use `plt.plot(x,y, args**)` for ploting something at coordinate $(x,y)$ (see code for more example)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "### Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import random as rd\n",
    "import time\n",
    "\n",
    "from gym import Env, spaces\n",
    "\n",
    "# For saving files\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "### Coor class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Coor():\n",
    "    def __init__(self, coor):\n",
    "        self.x = coor[0]\n",
    "        self.y = coor[1]\n",
    "\n",
    "    def get(self):\n",
    "        return self.x, self.y\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"(\" + str(self.x) + \", \" + str(self.y) + \")\"\n",
    "    \n",
    "    def __add__(self, coor2):\n",
    "        return Coor((self.x + coor2.x, self.y + coor2.y))\n",
    "    \n",
    "    def __eq__(self, coor2):\n",
    "        if coor2 == None:\n",
    "            return False\n",
    "        return (self.x==coor2.x) and (self.y==coor2.y)\n",
    "    \n",
    "    def __neg__(self):\n",
    "        x,y = self.get()\n",
    "        return Coor((-x,-y))\n",
    "    \n",
    "    def __sub__(self, coor2):\n",
    "        coor = - coor2\n",
    "        return self + coor\n",
    "    \n",
    "    def norm(self):\n",
    "        x,y = self.get()\n",
    "        return np.sqrt(x*x + y*y)\n",
    "    \n",
    "    def dist(self, coor2):\n",
    "        return (self -coor2).norm()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contrary to previous environment, track are not matrix anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersect(coorA,coorB,coorC,coorD):\n",
    "    # Return true if line segments AB and CD intersect\n",
    "    def ccw(coorA, coorB, coorC):\n",
    "        return (coorC.y-coorA.y) * (coorB.x-coorA.x) > (coorB.y-coorA.y) * (coorC.x-coorA.x)\n",
    "    return ccw(coorA,coorC,coorD) != ccw(coorB,coorC,coorD) and ccw(coorA,coorB,coorC) != ccw(coorA,coorB,coorD)\n",
    "\n",
    "# n = 10\n",
    "# random_coor = lambda a,b : Coor((rd.randint(a,b), rd.randint(a,b)))\n",
    "# for i in range(10):\n",
    "#     a = random_coor(i*n, (i+1)*n)\n",
    "#     b = random_coor(i*n, (i+1)*n)\n",
    "#     c = random_coor(i*n, (i+1)*n)\n",
    "#     d = random_coor(i*n, (i+1)*n)\n",
    "#     color = \"green\"\n",
    "#     if intersect(a,b,c,d):\n",
    "#         color = \"red\"\n",
    "#     plt.plot([a.x, b.x], [a.y,b.y], \"-o\", color=color, markersize=2)\n",
    "#     plt.plot([c.x, d.x], [c.y,d.y], \"-o\", color=color, markersize=2)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RED = [255, 0, 0]\n",
    "GREEN = [0, 255, 0]\n",
    "BLUE = [0, 0, 255]\n",
    "GREY = [70 for _ in range(3)]\n",
    "WHITE = [240 for _ in range(3)]\n",
    "\n",
    "START_CHAR = 2\n",
    "CAR_CHAR = 4\n",
    "\n",
    "def color_track(b):\n",
    "    if b == START_CHAR:\n",
    "        return GREEN\n",
    "    elif b == 1:\n",
    "        return GREY\n",
    "    else:\n",
    "        return WHITE\n",
    "    \n",
    "\n",
    "class Track():\n",
    "    def __init__(self, tab, l_bt_lines=8, nb_lines=1, compute_lines=True):\n",
    "        \"\"\" Track class\n",
    "        \n",
    "        l_bt_lines is the space between two lines\n",
    "\n",
    "        nb_lines is tej inverse of the ratio you want to keep each lines\n",
    "        i.e. nblines=n => keep on 1/n lines\n",
    "        \"\"\"\n",
    "\n",
    "        #switching height and width for plan approach\n",
    "        self.height, self.width = np.array(tab).shape\n",
    "        self.basic_info_track:list = np.array(tab)\n",
    "        \n",
    "        self.info_track:list = [[0 for _ in range(self.height)] for _ in range(self.width)]\n",
    "        for x in range(self.width):\n",
    "            for y in range(self.height):\n",
    "                self.info_track[x][y] = self.basic_info_track[self.height-1-y][x]\n",
    "\n",
    "        self.color_track = [[color_track(self.info_track[x][y]) for x in range(self.width)] for y in range(self.height)]\n",
    "\n",
    "        self.start = None\n",
    "        for y in range(self.height):\n",
    "            for x in range(self.width):\n",
    "                if self.info_track[x][y] == START_CHAR:\n",
    "                    self.start = Coor((x,y))\n",
    "\n",
    "        self.basic_alpha = 0\n",
    "    \n",
    "        self.nb_lines = nb_lines\n",
    "        self.lenght_bt_lines = l_bt_lines\n",
    "\n",
    "        self.midpoints = []\n",
    "        self.lines = []\n",
    "        if compute_lines:\n",
    "            self.midpoints, self.lines = self.create_lines(self.start)\n",
    "            self.lines = [x for i,x in enumerate(self.lines) if i%nb_lines==0]\n",
    "        \n",
    "\n",
    "    def create_lines(self, coor:Coor):\n",
    "        liste_coor = [coor]\n",
    "        lines = []\n",
    "        alpha = 0\n",
    "\n",
    "        running = True\n",
    "        while True:\n",
    "            line, next_alpha, new_coor = self.create_line(liste_coor[-1])\n",
    "            #plt.plot(liste_coor[-1].x, liste_coor[-1].y, \"o\", color=\"limegreen\", markersize=3)\n",
    "            liste_coor[-1] = new_coor\n",
    "\n",
    "            coor_alpha = Coor((np.cos(alpha*np.pi/180), np.sin(alpha*np.pi/180)))\n",
    "            coor_next_alpha = Coor((np.cos(next_alpha*np.pi/180), np.sin(next_alpha*np.pi/180)))\n",
    "            if coor_alpha.x*coor_next_alpha.x + coor_alpha.y*coor_next_alpha.y<0:\n",
    "                next_alpha = (next_alpha + 180) %360\n",
    "\n",
    "            dx = np.cos(next_alpha*np.pi/180) * self.lenght_bt_lines\n",
    "            dy = np.sin(next_alpha*np.pi/180) * self.lenght_bt_lines\n",
    "            next_coor = Coor((dx,dy)) + liste_coor[-1]\n",
    "            \n",
    "\n",
    "            liste_coor.append(next_coor)\n",
    "            lines.append(line)\n",
    "            alpha = next_alpha\n",
    "            \n",
    "            if (not running) and intersect(new_coor, next_coor, lines[0][0], lines[0][1]):\n",
    "                break\n",
    "            running = False\n",
    "            \n",
    "        return liste_coor, lines\n",
    "\n",
    "\n",
    "    def create_line(self, base_coor):\n",
    "        min_lenght = self.height + self.width\n",
    "        for alpha in range(0, 180):\n",
    "            coor1_act = self.next_wall(base_coor, alpha)\n",
    "            coor2_act = self.next_wall(base_coor, alpha+180)\n",
    "            lenght_act = coor1_act.dist(coor2_act)\n",
    "\n",
    "            if lenght_act<min_lenght:\n",
    "                coor1 = Coor((coor1_act.x, coor1_act.y))\n",
    "                coor2 = Coor((coor2_act.x, coor2_act.y))\n",
    "                min_lenght = lenght_act\n",
    "                basic_alpha = alpha-90\n",
    "\n",
    "        return (coor1, coor2), basic_alpha, Coor(((coor1.x + coor2.x)/2, (coor1.y + coor2.y)/2 ))\n",
    "\n",
    "    def get_color(self, coor:Coor):\n",
    "        \"\"\"return the color of the case x,y\"\"\"\n",
    "        x,y = coor.get()\n",
    "        return color_track(self.info_track[x][y])\n",
    "    \n",
    "    def is_wall(self, coor:Coor):\n",
    "        \"\"\"Return True if case (x,y) is a wall\"\"\"\n",
    "        x,y = coor.get()\n",
    "        nx,ny = int(round(x)), int(round(y))\n",
    "        return (self.info_track[nx][ny] == 1)\n",
    "\n",
    "    def get_start(self):\n",
    "        \"\"\"Return coordinate of start\"\"\"\n",
    "        if self.start == None:\n",
    "            return None\n",
    "        return self.start.get()\n",
    "    \n",
    "    def get_end(self):\n",
    "        \"\"\"Return coordinate of end\"\"\"\n",
    "        return self.end.get()\n",
    "    \n",
    "    def is_case_ridable(self, coor: Coor):\n",
    "        \"\"\"Return if the car can go on the coordinate or not\"\"\"\n",
    "        x,y = coor.get()\n",
    "        x,y = int(round(x)), int(round(y))\n",
    "        if not (x>=0 and x<self.width and y>=0 and y<self.height):\n",
    "            return False\n",
    "        return not self.is_wall(coor)\n",
    "    \n",
    "    def is_move_possible(self, a:Coor, b:Coor) -> bool:\n",
    "        \"\"\"Return if the car can go from point a to b in straight line\"\"\"\n",
    "        diff_x = b.x-a.x\n",
    "        diff_y = b.y-a.y\n",
    "\n",
    "        d = a.dist(b)\n",
    "        if d<1:\n",
    "            d = 1\n",
    "        \n",
    "        space = np.arange(0, 1, 1/d)\n",
    "        for t in space:\n",
    "            case = Coor((a.x+t*diff_x, a.y+t*diff_y))\n",
    "            if not self.is_case_ridable(case):\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    def is_case_in(self, coor:Coor):\n",
    "        \"\"\"return True is coor is in the tab\"\"\"\n",
    "        return coor.x>=0 and coor.x<self.width and coor.y>=0 and coor.y<self.height\n",
    "    \n",
    "    def next_road(self, coor:Coor, alpha:float, dist_max=None):\n",
    "        \"\"\"Return the next in the line from coor to the first wall\"\"\"\n",
    "        alpha = alpha % 360\n",
    "        dx = np.cos(alpha * np.pi/180)\n",
    "        dy = np.sin(alpha * np.pi/180)\n",
    "\n",
    "        i = 0\n",
    "        next_coor = Coor( (int(round(coor.x + i*dx)), int(round(coor.y + i*dy))) )\n",
    "        while not self.is_case_ridable(next_coor):\n",
    "            if ((dist_max!=None) and (coor.dist(next_coor) > dist_max)) or (not self.is_case_in(next_coor)):\n",
    "                return None\n",
    "            i += 1\n",
    "            next_coor  = Coor( (int(round(coor.x + i*dx)), int(round(coor.y + i*dy))) )\n",
    "        return next_coor\n",
    "\n",
    "    def next_wall(self, coor:Coor, alpha:float, dist_max=None):\n",
    "        \"\"\"Return the next in the line from coor to the first wall\"\"\"\n",
    "        alpha = alpha % 360\n",
    "        dx = np.cos(alpha * np.pi/180)\n",
    "        dy = np.sin(alpha * np.pi/180)\n",
    "\n",
    "        i = 0\n",
    "        next_coor = Coor( (int(round(coor.x + i*dx)), int(round(coor.y + i*dy))) )\n",
    "        while self.is_case_ridable(next_coor):\n",
    "            if (dist_max!=None) and (coor.dist(next_coor) > dist_max):\n",
    "                break\n",
    "            i += 1\n",
    "            next_coor  = Coor( (int(round(coor.x + i*dx)), int(round(coor.y + i*dy))) )\n",
    "        return next_coor\n",
    "\n",
    "    def plot(self, hide=False, show_lines=False, show_midpoints=False):\n",
    "        \"\"\"Plot the track using matplotlib\"\"\"\n",
    "        plt.imshow(self.color_track, origin='lower')\n",
    "\n",
    "        if show_lines:\n",
    "            for i in self.lines:\n",
    "                liste_x = [coor.x for coor in i]\n",
    "                liste_y = [coor.y for coor in i]\n",
    "                plt.plot(liste_x, liste_y, '-', color=\"lightblue\")\n",
    "\n",
    "        if show_midpoints:\n",
    "            for i in self.midpoints:\n",
    "                plt.plot(i.x, i.y, 'o', color=\"lightblue\", markersize=3)\n",
    "\n",
    "        plt.plot(self.start.x, self.start.y, \"o\", color=\"limegreen\")\n",
    "            \n",
    "        plt.axis(\"off\")\n",
    "        if not hide:\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../tracks/02.png\"\n",
    "\n",
    "from matplotlib.image import imread\n",
    "from PIL import Image\n",
    "\n",
    "def info_from_real_color(tab):\n",
    "    x,y,z = tab[0], tab[1], tab[2]\n",
    "    if x==0 and y==0 and z==0:\n",
    "        return 1\n",
    "    elif np.sqrt((x-255)**2 + (y-255)**2 + (z-255)**2) <= 25:\n",
    "    #elif x==255 and y==255 and z==255:\n",
    "        return START_CHAR\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def crop(tab):\n",
    "    start = None\n",
    "    for i,x in enumerate(tab):\n",
    "        for j,y in enumerate(x):\n",
    "            if y==START_CHAR:\n",
    "                start = Coor((i,j))\n",
    "    mini = Coor((start.x, start.y))\n",
    "    maxi = Coor((start.x, start.y))\n",
    "\n",
    "    for i,x in enumerate(tab):\n",
    "        for j,y in enumerate(x):\n",
    "            if y==0:\n",
    "                if i<mini.x:\n",
    "                    mini.x = i\n",
    "                if j<mini.y:\n",
    "                    mini.y = j\n",
    "                if i>maxi.x:\n",
    "                    maxi.x = i\n",
    "                if j>maxi.y:\n",
    "                    maxi.y=j\n",
    "    \n",
    "    k = 2\n",
    "    res = [[y for j,y in enumerate(x) if mini.y-k<=j<=maxi.y+k] for i,x in enumerate(tab) if mini.x-k<=i<=maxi.x+k]\n",
    "    return res\n",
    "\n",
    "def create_track_info(path):\n",
    "    img = Image.open(path)\n",
    "    arr = np.array(img)\n",
    "    img.close()\n",
    "    return crop([[info_from_real_color(y) for y in x] for x in arr])\n",
    "\n",
    "basic_track = Track(create_track_info(\"../tracks/02.png\"), nb_lines=2, l_bt_lines=8)\n",
    "#basic_track.plot(show_lines=True, show_midpoints=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving tracks lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal here is to store all the tracks lines in .txt file so that we don't have to recalculate them.\n",
    "\n",
    "The format is the following: each lines contain four number a,b,c,d which reprenset point (a,b) and (c,d) of a line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tracks: 87\n",
      "[('../tracks2/post_images/01.png', '01'), ('../tracks2/post_images/02.png', '02'), ('../tracks2/post_images/03.png', '03'), ('../tracks2/post_images/04.png', '04'), ('../tracks2/post_images/05.png', '05'), ('../tracks2/post_images/06.png', '06'), ('../tracks2/post_images/07.png', '07'), ('../tracks2/post_images/08.png', '08'), ('../tracks2/post_images/09.png', '09'), ('../tracks2/post_images/10.png', '10'), ('../tracks2/post_images/11.png', '11'), ('../tracks2/post_images/12.png', '12'), ('../tracks2/post_images/13.png', '13'), ('../tracks2/post_images/14.png', '14'), ('../tracks2/post_images/15.png', '15'), ('../tracks2/post_images/16.png', '16'), ('../tracks2/post_images/17.png', '17'), ('../tracks2/post_images/18.png', '18'), ('../tracks2/post_images/19.png', '19'), ('../tracks2/post_images/20.png', '20'), ('../tracks2/post_images/21.png', '21'), ('../tracks2/post_images/22.png', '22'), ('../tracks2/post_images/23.png', '23'), ('../tracks2/post_images/24.png', '24'), ('../tracks2/post_images/25.png', '25'), ('../tracks2/post_images/26.png', '26'), ('../tracks2/post_images/27.png', '27'), ('../tracks2/post_images/28.png', '28'), ('../tracks2/post_images/30.png', '30'), ('../tracks2/post_images/31.png', '31'), ('../tracks2/post_images/32.png', '32'), ('../tracks2/post_images/33.png', '33'), ('../tracks2/post_images/34.png', '34'), ('../tracks2/post_images/35.png', '35'), ('../tracks2/post_images/36.png', '36'), ('../tracks2/post_images/37.png', '37'), ('../tracks2/post_images/38.png', '38'), ('../tracks2/post_images/39.png', '39'), ('../tracks2/post_images/41.png', '41'), ('../tracks2/post_images/42.png', '42'), ('../tracks2/post_images/43.png', '43'), ('../tracks2/post_images/44.png', '44'), ('../tracks2/post_images/45.png', '45'), ('../tracks2/post_images/46.png', '46'), ('../tracks2/post_images/47.png', '47'), ('../tracks2/post_images/48.png', '48'), ('../tracks2/post_images/50.png', '50'), ('../tracks2/post_images/51.png', '51'), ('../tracks2/post_images/52.png', '52'), ('../tracks2/post_images/53.png', '53'), ('../tracks2/post_images/54.png', '54'), ('../tracks2/post_images/55.png', '55'), ('../tracks2/post_images/56.png', '56'), ('../tracks2/post_images/57.png', '57'), ('../tracks2/post_images/58.png', '58'), ('../tracks2/post_images/59.png', '59'), ('../tracks2/post_images/60.png', '60'), ('../tracks2/post_images/61.png', '61'), ('../tracks2/post_images/62.png', '62'), ('../tracks2/post_images/63.png', '63'), ('../tracks2/post_images/64.png', '64'), ('../tracks2/post_images/66.png', '66'), ('../tracks2/post_images/67.png', '67'), ('../tracks2/post_images/68.png', '68'), ('../tracks2/post_images/69.png', '69'), ('../tracks2/post_images/70.png', '70'), ('../tracks2/post_images/71.png', '71'), ('../tracks2/post_images/72.png', '72'), ('../tracks2/post_images/73.png', '73'), ('../tracks2/post_images/74.png', '74'), ('../tracks2/post_images/75.png', '75'), ('../tracks2/post_images/76.png', '76'), ('../tracks2/post_images/77.png', '77'), ('../tracks2/post_images/78.png', '78'), ('../tracks2/post_images/79.png', '79'), ('../tracks2/post_images/80.png', '80'), ('../tracks2/post_images/81.png', '81'), ('../tracks2/post_images/82.png', '82'), ('../tracks2/post_images/83.png', '83'), ('../tracks2/post_images/85.png', '85'), ('../tracks2/post_images/86.png', '86'), ('../tracks2/post_images/87.png', '87'), ('../tracks2/post_images/88.png', '88'), ('../tracks2/post_images/89.png', '89'), ('../tracks2/post_images/90.png', '90'), ('../tracks2/post_images/91.png', '91'), ('../tracks2/post_images/93.png', '93')]\n",
      "../tracks2/post_images/01.png as 114 lines\n",
      "../tracks2/post_images/02.png as 132 lines\n",
      "../tracks2/post_images/03.png as 107 lines\n",
      "../tracks2/post_images/04.png as 96 lines\n",
      "../tracks2/post_images/05.png as 122 lines\n",
      "../tracks2/post_images/06.png as 152 lines\n",
      "../tracks2/post_images/07.png as 134 lines\n",
      "../tracks2/post_images/08.png as 72 lines\n",
      "../tracks2/post_images/09.png as 102 lines\n",
      "../tracks2/post_images/10.png as 78 lines\n",
      "../tracks2/post_images/11.png as 122 lines\n",
      "../tracks2/post_images/12.png as 130 lines\n",
      "../tracks2/post_images/13.png as 116 lines\n",
      "../tracks2/post_images/14.png as 117 lines\n",
      "../tracks2/post_images/15.png as 106 lines\n",
      "../tracks2/post_images/16.png as 147 lines\n",
      "../tracks2/post_images/17.png as 95 lines\n",
      "../tracks2/post_images/18.png as 138 lines\n",
      "../tracks2/post_images/19.png as 89 lines\n",
      "../tracks2/post_images/20.png as 108 lines\n",
      "../tracks2/post_images/21.png as 82 lines\n",
      "../tracks2/post_images/22.png as 95 lines\n",
      "../tracks2/post_images/23.png as 100 lines\n",
      "../tracks2/post_images/24.png as 122 lines\n",
      "../tracks2/post_images/25.png as 77 lines\n",
      "../tracks2/post_images/26.png as 100 lines\n",
      "../tracks2/post_images/27.png as 94 lines\n",
      "../tracks2/post_images/28.png as 101 lines\n",
      "../tracks2/post_images/30.png as 170 lines\n",
      "../tracks2/post_images/31.png as 104 lines\n",
      "../tracks2/post_images/32.png as 109 lines\n",
      "../tracks2/post_images/33.png as 107 lines\n",
      "../tracks2/post_images/34.png as 106 lines\n",
      "../tracks2/post_images/35.png as 94 lines\n",
      "../tracks2/post_images/36.png as 103 lines\n",
      "../tracks2/post_images/37.png as 119 lines\n",
      "../tracks2/post_images/38.png as 169 lines\n",
      "../tracks2/post_images/39.png as 161 lines\n",
      "../tracks2/post_images/41.png as 105 lines\n",
      "../tracks2/post_images/42.png as 93 lines\n",
      "../tracks2/post_images/43.png as 95 lines\n",
      "../tracks2/post_images/44.png as 97 lines\n",
      "../tracks2/post_images/45.png as 101 lines\n",
      "../tracks2/post_images/46.png as 116 lines\n",
      "../tracks2/post_images/47.png as 159 lines\n",
      "../tracks2/post_images/48.png as 114 lines\n",
      "../tracks2/post_images/50.png as 95 lines\n",
      "../tracks2/post_images/51.png as 92 lines\n",
      "../tracks2/post_images/52.png as 103 lines\n",
      "../tracks2/post_images/53.png as 96 lines\n",
      "../tracks2/post_images/54.png as 101 lines\n",
      "../tracks2/post_images/55.png as 105 lines\n",
      "../tracks2/post_images/56.png as 123 lines\n",
      "../tracks2/post_images/57.png as 100 lines\n",
      "../tracks2/post_images/58.png as 119 lines\n",
      "../tracks2/post_images/59.png as 109 lines\n",
      "../tracks2/post_images/60.png as 124 lines\n",
      "../tracks2/post_images/61.png as 110 lines\n",
      "../tracks2/post_images/62.png as 139 lines\n",
      "../tracks2/post_images/63.png as 118 lines\n",
      "../tracks2/post_images/64.png as 122 lines\n",
      "../tracks2/post_images/66.png as 107 lines\n",
      "../tracks2/post_images/67.png as 96 lines\n",
      "../tracks2/post_images/68.png as 113 lines\n",
      "../tracks2/post_images/69.png as 108 lines\n",
      "../tracks2/post_images/70.png as 132 lines\n",
      "../tracks2/post_images/71.png as 177 lines\n",
      "../tracks2/post_images/72.png as 115 lines\n",
      "../tracks2/post_images/73.png as 119 lines\n",
      "../tracks2/post_images/74.png as 101 lines\n",
      "../tracks2/post_images/75.png as 97 lines\n",
      "../tracks2/post_images/76.png as 99 lines\n",
      "../tracks2/post_images/77.png as 116 lines\n",
      "../tracks2/post_images/78.png as 106 lines\n",
      "../tracks2/post_images/79.png as 120 lines\n",
      "../tracks2/post_images/80.png as 102 lines\n",
      "../tracks2/post_images/81.png as 118 lines\n",
      "../tracks2/post_images/82.png as 108 lines\n",
      "../tracks2/post_images/83.png as 104 lines\n",
      "../tracks2/post_images/85.png as 102 lines\n",
      "../tracks2/post_images/86.png as 85 lines\n",
      "../tracks2/post_images/87.png as 95 lines\n",
      "../tracks2/post_images/88.png as 84 lines\n",
      "../tracks2/post_images/89.png as 90 lines\n",
      "../tracks2/post_images/90.png as 91 lines\n",
      "../tracks2/post_images/91.png as 107 lines\n",
      "../tracks2/post_images/93.png as 93 lines\n"
     ]
    }
   ],
   "source": [
    "from os import walk\n",
    "\n",
    "TRACKS_FOLDER = \"../tracks2/post_images/\"\n",
    "LINES_FOLDER = \"../track_lines/\"\n",
    "\n",
    "PATHS = []\n",
    "for (dirpath, dirnames, filenames) in walk(TRACKS_FOLDER):\n",
    "    for file in filenames:\n",
    "        file_path = TRACKS_FOLDER + file\n",
    "        PATHS.append((file_path, file[:-4]))\n",
    "    break\n",
    "\n",
    "PATHS.sort()\n",
    "# Tracks to del: 29, 40, 49, 65, 84, 92\n",
    "to_del = [29, 40, 49, 65, 84, 92]\n",
    "to_del.sort(key=lambda x:-x)\n",
    "for x in to_del:\n",
    "    del PATHS[x-1]\n",
    "\n",
    "#PATHS = PATHS[:10]\n",
    "\n",
    "print(\"Number of tracks:\", len(PATHS))\n",
    "print(PATHS)\n",
    "\n",
    "\n",
    "def save_lines(track:Track, path:str):\n",
    "    file = open(path, \"w\")\n",
    "    for c1,c2 in track.lines:\n",
    "        txt = str(c1.x) + \",\" + str(c1.y) + \",\" + str(c2.x) + \",\" + str(c2.y) +\"\\n\" \n",
    "        file.write(txt)\n",
    "    file.close()\n",
    "\n",
    "\n",
    "def save_tracks_lines():\n",
    "    # put all the tracks path here:\n",
    "    # The track called O3.png is not working because of unsmooth corner\n",
    "    for name, number in PATHS:\n",
    "        track_info = create_track_info(name)\n",
    "        track = Track(track_info, nb_lines=2, l_bt_lines=8)\n",
    "        save_lines(track, LINES_FOLDER + number + \".txt\")\n",
    "        print(name, number)\n",
    "\n",
    "\n",
    "def create_tracks():\n",
    "    tracks = []\n",
    "    for name, number in PATHS:\n",
    "        track_info = create_track_info(name)\n",
    "        track = Track(track_info, nb_lines=2, l_bt_lines=8, compute_lines=False)\n",
    "        file = open(LINES_FOLDER + number + \".txt\", \"r\")\n",
    "\n",
    "        for lines in file:\n",
    "            a,b,c,d = lines.split(\",\")\n",
    "            a,b,c,d = int(a), int(b), int(c), int(d)\n",
    "            c1 = Coor((a,b))\n",
    "            c2 = Coor((c,d))\n",
    "            track.lines.append((c1,c2))\n",
    "            track.midpoints.append(Coor(((c1.x+c2.x)/2, (c1.y+c2.y)/2)))\n",
    "        file.close()\n",
    "        tracks.append(track)\n",
    "\n",
    "        #tracks[-1].plot(show_lines=True, show_midpoints=True)\n",
    "        print(name, \"as\", len(tracks[-1].lines), \"lines\")\n",
    "\n",
    "    return tracks\n",
    "\n",
    "\n",
    "#save_tracks_lines() # uncomment to not recalculate lines\n",
    "\n",
    "TRACKS:list[Track] = create_tracks()\n",
    "\n",
    "#Do not execute next for saving tracks line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Car class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Car has $2$ main variable:\n",
    " - speed: $v$\n",
    " - alpha: $\\alpha$ suppose to be between $0$ and $360$\n",
    "\n",
    "To calculate the $x$-speed and $y$-speed we use the next formulas:\n",
    " - $v_x = v.cos(\\alpha . \\frac{\\pi}{180})$\n",
    " - $v_y = v.sin(\\alpha . \\frac{\\pi}{180})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Constant\"\"\"\n",
    "MAX_SPEED = 50\n",
    "MAX_TURN = 20\n",
    "\n",
    "\"\"\"Class\"\"\"\n",
    "class Car():\n",
    "    def __init__(self, coor:Coor, time):\n",
    "        self.coor: Coor = Coor((coor.x, coor.y))\n",
    "        self.speed: float = 0\n",
    "        self.alpha: float = 0 # The angle of the car according to unitary cicrle\n",
    "        self.trajectory = [[Coor((coor.x, coor.y)), 0]]\n",
    "        self.previous_speed: float = 0\n",
    "        self.time = time\n",
    "\n",
    "        self.max_turn = 20 * self.time\n",
    "        self.max_speed = 50 * self.time\n",
    "        self.acceleration_constant = 3 * self.time\n",
    "        self.brake_constant = 6 * self.time\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"C[\" + str(self.coor) + \" \" + str(self.speed) + \" \" + str(self.alpha) + \"]\"\n",
    "    \n",
    "\n",
    "    def accelerate(self, amont=1):\n",
    "        \"\"\"Increase speed of the car\"\"\"\n",
    "        self.speed += amont * self.acceleration_constant\n",
    "        self.speed = min(self.speed, self.max_speed)\n",
    "        \n",
    "\n",
    "    def brake(self, amont=1):\n",
    "        \"\"\"Decrease speed of the car (can't drive backward)\"\"\"\n",
    "        self.speed -= amont * self.brake_constant\n",
    "        if self.speed < 0:\n",
    "            self.speed = 0\n",
    "\n",
    "    def turn(self, deg):\n",
    "        \"\"\"Change the current rotation of the car\"\"\"\n",
    "        if np.absolute(deg) > self.max_turn:\n",
    "            print(deg)\n",
    "            assert False\n",
    "        self.alpha += deg\n",
    "        self.alpha = self.alpha % 360\n",
    "\n",
    "    def get_speed_coor(self):\n",
    "        cst: float = np.pi / 180\n",
    "        dx: float = self.speed * np.cos(self.alpha * cst)\n",
    "        dy: float = self.speed * np.sin(self.alpha * cst)\n",
    "        return Coor((dx,dy))\n",
    "\n",
    "    def move(self):\n",
    "        \"\"\"Change the coordinate of the care according to its speed and alpha\"\"\"\n",
    "        speed_increase = 0\n",
    "        if self.previous_speed < self.speed:\n",
    "            speed_increase = 1\n",
    "        elif self.previous_speed > self.speed:\n",
    "            speed_increase = -1\n",
    "        self.previous_speed = self.speed\n",
    "\n",
    "        dx,dy = self.get_speed_coor().get()\n",
    "        self.coor.x += dx\n",
    "        self.coor.y += dy\n",
    "        self.trajectory.append([Coor((self.coor.x, self.coor.y)), speed_increase])\n",
    "\n",
    "    def dic(self):\n",
    "        return {\"coor\":self.coor, \"speed\":self.speed, \"alpha\":self.alpha, \"trajectory\":self.trajectory}\n",
    "\n",
    "    def plot(self, markersize=8, vector_constant=2, show_trajectory=False, head_width=1):\n",
    "        \"\"\"Plot the car and is speed vectors\"\"\"\n",
    "        # Plot car\n",
    "        x,y = self.coor.get()\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        # Plot \n",
    "        if show_trajectory:\n",
    "            liste_x = [i[0].x for i in self.trajectory]\n",
    "            liste_y = [i[0].y for i in self.trajectory]\n",
    "\n",
    "            for i in range(1, len(self.trajectory)):\n",
    "                color = \"yellow\"\n",
    "                if self.trajectory[i][1] == 1:\n",
    "                    color = \"green\"\n",
    "                elif self.trajectory[i][1] == -1:\n",
    "                    color = \"red\"\n",
    "        \n",
    "                plt.plot([liste_x[i-1], liste_x[i]], [liste_y[i-1], liste_y[i]], \"-o\", color=color, markersize=2)\n",
    "                 \n",
    "        # Plot car's directoin\n",
    "        cst: float = np.pi / 180\n",
    "        dx: float = np.cos(self.alpha * cst)\n",
    "        dy: float = np.sin(self.alpha * cst)\n",
    "        plt.arrow(x, y, dx/10, dy/10, head_width=head_width)\n",
    "        plt.plot([x, x+ dx*self.speed*vector_constant], [y, y+ dy*self.speed*vector_constant], \"-\", color=\"red\")\n",
    "        plt.plot(x, y, \"o\", color='blue', markersize=markersize)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gym env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to transform a actual action $(a, \\alpha) \\in \\{-1,0,1\\} \\times \\{-K,...,K\\}$ where $K =$ `MAX_TURN` to a action in $\\{0,...,N-1\\}$.\n",
    "\n",
    "Then we need a bijection\n",
    "$$\\phi : \\{-1,0,1\\} \\times \\{-K,...,K\\} \\rightarrow \\mathbb{Z}_N$$\n",
    "\n",
    "We can take\n",
    "$$\\phi(a,b) = 3(b+K) + (a+1)$$\n",
    "\n",
    "Then,\n",
    "$$\\phi^{-1}(x) = ((x\\; mod\\; 3)-1, \\frac{1}{3}x -K)$$\n",
    "\n",
    "Moreover, we have $N = 3\\times 2K+1 = 6K+3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SPEED = 50\n",
    "MAX_TURN = 20\n",
    "\n",
    "class RacingCar(Env):\n",
    "    def __init__(self):\n",
    "        super(RacingCar, self).__init__()\n",
    "        # time between two frames\n",
    "        self.time = 0.9 #Change this variable to \"discretiser\" the time. Lower value means more discretisation\n",
    "\n",
    "        self.max_turn = int(MAX_TURN * self.time)\n",
    "        self.nb_state = 6*self.max_turn + 3\n",
    "        self.max_speed = int(MAX_SPEED * self.time)\n",
    "\n",
    "        # Define an action space ranging from 0 to 3\n",
    "        self.action_space = [self.int_to_action(i) for i in range(self.nb_state)]\n",
    "        self.int_action_space = [i for i in range(self.nb_state)]\n",
    "\n",
    "        self.track: Track = None\n",
    "        self.id_line_goal = 0\n",
    "\n",
    "        # Define the anle of which we will look the distance\n",
    "        self.liste_alpha = [60, 40, 20, 0, -20, -40, -60]\n",
    "        self.max_dist_wall = None\n",
    "\n",
    "        self.reward_max = 200\n",
    "        \n",
    "        self.car: Car = None\n",
    "\n",
    "    def create_car(self):\n",
    "        car = Car(self.track.start, self.time)\n",
    "        return car\n",
    "\n",
    "    def action_to_int(self, action):\n",
    "        \"\"\"Transform an action (tuple) into an action (int)\"\"\"\n",
    "        a,b = action\n",
    "        return 3*(b+self.max_turn) + a+1\n",
    "    \n",
    "    def int_to_action(self, x):\n",
    "        \"\"\"Transform an action (int) into an action (tuple)\"\"\"\n",
    "        return ((x%3)-1, int(x/3) -self.max_turn)\n",
    "\n",
    "\n",
    "    def get_state(self):\n",
    "        \"\"\"Return actual state of the env\"\"\"\n",
    "        state = [self.car.speed]\n",
    "        for alpha in self.liste_alpha:\n",
    "            coor = self.track.next_wall(self.car.coor, self.car.alpha + alpha, dist_max=self.max_dist_wall)\n",
    "            state.append(self.car.coor.dist(coor))\n",
    "        return state\n",
    "\n",
    "    def reset(self, track):\n",
    "        \"\"\"Reset the environment\"\"\"\n",
    "        self.id_line_goal = 0\n",
    "        self.track = track\n",
    "        self.max_dist_wall = self.track.height + self.track.width\n",
    "\n",
    "        self.car = self.create_car()\n",
    "        return self.get_state(), []\n",
    "\n",
    "    def render(self, waiting_time=0.01,\n",
    "               show_trajectory=False, show_dist_to_wall=False,\n",
    "               show_track_midpoint=False, show_track_lines=False):\n",
    "        \"\"\"Render the environment\"\"\"\n",
    "        self.track.plot(hide=True, show_lines=show_track_lines, show_midpoints=show_track_midpoint)\n",
    "        if show_dist_to_wall:\n",
    "            for alpha in self.liste_alpha:\n",
    "                coor = self.track.next_wall(self.car.coor, self.car.alpha + alpha, dist_max=self.max_dist_wall)\n",
    "                plt.plot([self.car.coor.x, coor.x], [self.car.coor.y, coor.y], \"-\", color=\"grey\")\n",
    "\n",
    "        self.car.plot(show_trajectory=show_trajectory)\n",
    "        display.clear_output(wait=True)\n",
    "        plt.show()\n",
    "        time.sleep(waiting_time)\n",
    "        \n",
    "    def step(self, action:int):\n",
    "        \"\"\"Do a step, we suppose that the action is a possible one\"\"\"\n",
    "        is_done = False\n",
    "        reward = 0\n",
    "\n",
    "        x,y = self.car.coor.get()\n",
    "        previous_coor = Coor((x,y))\n",
    "\n",
    "        acc, turn = self.int_to_action(action)\n",
    "        if acc==-1:\n",
    "            self.car.brake()\n",
    "        elif acc==1:\n",
    "            self.car.accelerate()\n",
    "        self.car.turn(turn)\n",
    "        self.car.move()\n",
    "\n",
    "        new_coor = self.car.coor\n",
    "\n",
    "        has_crashed = False\n",
    "        if not self.track.is_move_possible(previous_coor, new_coor):\n",
    "            has_crashed = True\n",
    "            reward -= 500\n",
    "            is_done = True\n",
    "\n",
    "        if self.car.speed == 0:\n",
    "            reward -= 10\n",
    "        \n",
    "        reward += self.car.speed/10\n",
    "        \n",
    "        previous_id = (self.id_line_goal-1) % (len(self.track.lines))\n",
    "\n",
    "        if intersect(self.track.lines[previous_id][0], self.track.lines[previous_id][1], previous_coor, new_coor):\n",
    "            reward -= 200\n",
    "            is_done = True\n",
    "\n",
    "        while intersect(self.track.lines[self.id_line_goal][0], self.track.lines[self.id_line_goal][1], previous_coor, new_coor) and not has_crashed:\n",
    "            reward += 10\n",
    "            self.id_line_goal = (self.id_line_goal + 1) % (len(self.track.lines))\n",
    "\n",
    "        reward -= 1\n",
    "        return self.get_state(), reward, is_done, has_crashed, []\n",
    "    \n",
    "    def random_action(self, p_accel=0.25, p_brake=0.25, p_turn=0.5):\n",
    "        \"\"\"Return random possible action according to probability\"\"\"\n",
    "        action = [0,0]\n",
    "        rd_accel = rd.random()\n",
    "        if rd_accel <= p_accel:\n",
    "            action[0] = 1\n",
    "        elif rd_accel <= p_accel + p_brake:\n",
    "            action[0] = -1\n",
    "        \n",
    "        if rd.random() <= p_turn:\n",
    "            action[1] = ((-1)**(rd.randint(0,1))) * rd.randint(-self.max_turn, self.max_turn)\n",
    "        return tuple(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Env example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = RacingCar()\n",
    "# env.reset(basic_track)\n",
    "# env.track.plot(show_lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# print(env.nb_state)\n",
    "# print(env.action_space)\n",
    "# for i in range(env.nb_state):\n",
    "#     acc,turn = env.int_to_action(i)\n",
    "#     if (np.absolute(turn) > env.max_turn) or (np.absolute(env.action_space[i][1]) > env.max_turn):\n",
    "#         assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moves = [[Coor((60, 25)), Coor((100,28))],\n",
    "#          [Coor((125, 60)), Coor((105, 80))],\n",
    "#          [Coor((240,160)), Coor((180, 110))],\n",
    "#          [Coor((363.5,140)), Coor((359.2, 260))],\n",
    "#          [Coor((240, 230)), Coor((240, 230))],\n",
    "#          [Coor((290, 200)), Coor((290, 200))]]\n",
    "\n",
    "# for coors in moves:\n",
    "#     res = env.track.is_move_possible(coors[0], coors[1])\n",
    "#     color = \"limegreen\"\n",
    "#     if not res:\n",
    "#         color = \"red\"\n",
    "#     plt.plot([coors[0].x, coors[1].x], [coors[0].y, coors[1].y], \"-o\", markersize=4, color=color)\n",
    "\n",
    "# env.track.plot(hide=True)\n",
    "# plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.reset(basic_track)\n",
    "\n",
    "# actions = [(1,-5), (1, -10), (1,0), (1,0), (1,10), (1, 10), (1,0), (1,0),\n",
    "#            (1, env.max_turn), (1, env.max_turn), (-1, env.max_turn), (-1, env.max_turn), (-1, 0), (-1, 0), (-1, 0),\n",
    "#            (-1, 0), (-1, 0), (-1, 0), (-1, 0),\n",
    "#            (-1, -env.max_turn), (-1, -env.max_turn), (-1, -env.max_turn), (-1, -env.max_turn), (-1, -env.max_turn), (-1, -env.max_turn),\n",
    "#            (-1, -env.max_turn), (-1, -env.max_turn), (-1, -env.max_turn), (-1, -env.max_turn),\n",
    "#            (1, 0), (1, 0), (1, 0), (1, 0), (1, 0)]\n",
    "\n",
    "# reward_list = []\n",
    "# for action in actions:\n",
    "#     if np.absolute(action[1]) <= env.max_turn:\n",
    "#         _, reward, _, _, _= env.step(env.action_to_int(action))\n",
    "#         reward_list.append(int(reward*100)/100)\n",
    "#         env.render(show_trajectory=True, show_dist_to_wall=True, show_track_lines=True)\n",
    "    \n",
    "# print(env.get_state())\n",
    "# print(reward_list)\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reset example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the env\n",
    "env = RacingCar()\n",
    "\n",
    "# tracks is a list comporting all tracks\n",
    "# choose a index of the list\n",
    "id = rd.randint(0, len(TRACKS)-1)\n",
    "\n",
    "# reset the env with the track\n",
    "env.reset(TRACKS[id])\n",
    "\n",
    "# Render with some options\n",
    "#env.render(show_dist_to_wall=True, show_track_lines=True)\n",
    "\n",
    "# Close the env\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essentials for training and env\n",
    "\n",
    "# For NN\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# For math computations\n",
    "# import numpy as np\n",
    "\n",
    "# For random as rd\n",
    "# import random \n",
    "\n",
    "# For envs\n",
    "# import gymnasium\n",
    "\n",
    "# For time limit\n",
    "# import time\n",
    "\n",
    "# structure to save transitions \n",
    "from collections import namedtuple , deque\n",
    "Transition = namedtuple(\"Transition\",[\"state\",\"action\",\"next_state\",\"reward\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For plots\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "from IPython import display\n",
    "\n",
    "# For saving files\n",
    "from datetime import datetime\n",
    "\n",
    "# for model vizualisation \n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory():\n",
    "    def __init__(self,maxlen : int):\n",
    "        self.memory_ = deque(maxlen=maxlen)\n",
    "\n",
    "    def push(self,x : Transition):\n",
    "        self.memory_.append(x)\n",
    "\n",
    "    def sample(self,batch_size : int) -> list[Transition]:\n",
    "        return rd.sample(self.memory_,batch_size)\n",
    "    \n",
    "    def clear(self):\n",
    "        return self.memory_.clear()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self,layer_size,state_size,action_n):\n",
    "        super(DQN,self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(state_size,layer_size),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(layer_size,layer_size),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(layer_size,layer_size),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(layer_size,action_n),\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.network(x)\n",
    "    \n",
    "    def save(self,filename : str = None):\n",
    "        if (filename == None):\n",
    "            filename = datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "        torch.save(self.state_dict(),filename)\n",
    "\n",
    "    def load(self,filename : str):\n",
    "        self.load_state_dict(torch.load(filename, weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Env():\n",
    "    def __init__(self):\n",
    "        \"\"\" track_name is the name of the track file\"\"\"\n",
    "        # Toujours là\n",
    "        self.done = False\n",
    "\n",
    "        # Pour faire step, reset, state pour cette implementation\n",
    "        self.env = RacingCar()\n",
    "        self.state_gym,_ = self.env.reset(TRACKS[0])\n",
    "        self.n_action = self.env.nb_state\n",
    "\n",
    "        # Décrit le model actuel\n",
    "        self.model = DQN(400,8,self.n_action)\n",
    "\n",
    "        # Décrit les transitions observées jusqu'à présent\n",
    "        self.memory = ReplayMemory(10000)\n",
    "\n",
    "        # Pour normaliser la Q table\n",
    "        self.discount_factor = 0.9\n",
    "\n",
    "        self.track_for_training = int(len(TRACKS)*0.8)\n",
    "\n",
    "    def state(self):\n",
    "        \"\"\" On définit un état comme étant un batch de taille 1 ou None\"\"\"\n",
    "        if (self.state_gym == None or self.done) :\n",
    "            return None\n",
    "        else :\n",
    "            arr = np.array(self.env.get_state())\n",
    "            arr = arr / max(MAX_SPEED, self.env.max_dist_wall) #To normalize the array\n",
    "            return torch.tensor([arr],dtype=torch.float)\n",
    "\n",
    "    def show_state(self):\n",
    "        self.env.render(show_trajectory=True)\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset the environment\"\"\"\n",
    "        rd_track = rd.randint(0, self.track_for_training -1)\n",
    "        self.state_gym , _ = self.env.reset(TRACKS[rd_track])\n",
    "        self.done = False\n",
    "    \n",
    "    def dist(state):\n",
    "        \"\"\"Calcule la longueur d'un plus court chemin entre state et goal (sous forme d'un flotant)\"\"\"\n",
    "        goal = torch.tensor([[11,3]],dtype=torch.float)\n",
    "        start = torch.tensor([[0,3]],dtype=torch.float)\n",
    "        if (torch.equal(state,start)):\n",
    "           return torch.tensor(13,dtype=torch.float)\n",
    "        else :\n",
    "           return torch.sum(torch.abs(state-goal))\n",
    "       \n",
    "    def step(self,action : torch.tensor) :\n",
    "        \"\"\" Fais un pas depuis l'état actuel via l'action donnée et renvoit la transition observéex\n",
    "            Une action est un tenseur contenant un seul scalaire \"\"\"\n",
    "        if (self.done):\n",
    "            raise(ValueError(\"Trying to move from a final state\"))\n",
    "\n",
    "        prev_state = self.state()\n",
    "\n",
    "        # do the step and update the new gym state\n",
    "        acc, turn = self.env.int_to_action(action.item())\n",
    "        if np.absolute(turn) > self.env.max_turn:\n",
    "            print(action.item(), (acc, turn))\n",
    "            \n",
    "        self.state_gym,reward,terminated,truncated,_ = self.env.step(action.item())\n",
    "        self.done = terminated or truncated\n",
    "\n",
    "        next_state = self.state()\n",
    "\n",
    "        reward_normalizer = self.env.reward_max\n",
    "        qtable_normalizer = 1/(1-self.discount_factor)\n",
    "        reward = torch.tensor(reward/(reward_normalizer*qtable_normalizer), dtype=torch.float).reshape((1,1))\n",
    "        action = torch.tensor(action.item()).reshape((1,1))\n",
    "\n",
    "        transition = Transition(prev_state, action, next_state , reward)\n",
    "        return transition\n",
    "    \n",
    "    def policy(self):\n",
    "        if (self.done):\n",
    "            raise(ValueError(\"Trying to predict a move from a final state\"))\n",
    "        return self.model(self.state()).max(1).indices.reshape((1,1))\n",
    "    \n",
    "    def random_action(self) -> torch.tensor :\n",
    "        if (self.done):\n",
    "            raise(ValueError(\"Trying to sample a move from a final state\"))\n",
    "        action = rd.randint(0,self.n_action-1)\n",
    "        return torch.tensor(action).reshape((1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(env : Env,optimizer,criterion,batch_size,discount_factor):\n",
    "    if (len(env.memory) < batch_size) :\n",
    "        return \n",
    "\n",
    "    # A list of batch_size transtions\n",
    "    transition = env.memory.sample(batch_size)\n",
    "\n",
    "    # A tuple with four coordinates : \n",
    "    # state -> a batch of size batch_size of states \n",
    "    # action -> a batch of size batch_size of actions\n",
    "    # ect\n",
    "    batch = Transition(*zip(*transition))\n",
    "\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Batch of size batch_size of the Qvalue predicted by our current model, for the state and action of a transtion\n",
    "    predicted = env.model(state_batch).gather(1,action_batch)\n",
    "\n",
    "    next_state_value = torch.zeros((batch_size,1))\n",
    "\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None, batch.next_state)), dtype=torch.bool )\n",
    "    if non_final_mask.any():\n",
    "        non_final_next_state = torch.cat([s for s in batch.next_state if s is not None])\n",
    "        with torch.no_grad():\n",
    "            next_state_value[non_final_mask] = env.model(non_final_next_state).max(1).values.unsqueeze(1)\n",
    "\n",
    "    expected = reward_batch + (discount_factor * next_state_value)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(predicted,expected)\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_value_(env.model.parameters(), 100)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_policy_time(env) :\n",
    "    env.reset()\n",
    "    time_deb = time.perf_counter()\n",
    "    env.policy()\n",
    "    return time.perf_counter() - time_deb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_model_size(env):\n",
    "    return sum(p.numel() for p in env.model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_reward(env):\n",
    "    sum = 0\n",
    "    max_step = 300\n",
    "    for i in range(env.track_for_training,len(TRACKS)) :\n",
    "        env.state_gym , _ = env.env.reset(TRACKS[i])\n",
    "        env.done = False\n",
    "        i = 0\n",
    "        while(i < max_step and not(env.done)) :\n",
    "            i+=1\n",
    "            transition = env.step( env.policy() )\n",
    "            sum += transition.reward.item()\n",
    "    return sum/( len(TRACKS) - env.track_for_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(lr=1e-4,epsilon_decay=30.,batch_size = 40,time_bound = 60*(1),track_budget=int(0.8*len(TRACKS))):\n",
    "    #env.model.load(filename)\n",
    "    env = Env()\n",
    "    filename =  \"saved_model/\"  + datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "\n",
    "    # track budget for training\n",
    "    env.track_for_training = track_budget\n",
    "\n",
    "    # Hyperparameters\n",
    "    #batch_size = 40\n",
    "    epochs = 5000\n",
    "    max_episode_duration = 1000 * 1/env.env.time\n",
    "    epsilon_max = 1\n",
    "    epsilon_min = 0.01\n",
    "    #epsilon_decay = 30.\n",
    "    #lr = 1e-4\n",
    "    discount_factor = 0.9\n",
    "    env.discount_factor = discount_factor\n",
    "    optimizer = optim.AdamW(env.model.parameters(), lr=lr, amsgrad=True)\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "\n",
    "    env.memory.clear()\n",
    "\n",
    "    reward_history = []\n",
    "    reward_time = []\n",
    "    volatility_history = []\n",
    "    volatility_time = []\n",
    "\n",
    "    #time_bound = 60*(1)\n",
    "    time_start = time.perf_counter()\n",
    "    i = 0\n",
    "    while ( (time.perf_counter() - time_start <= time_bound)  ):\n",
    "        i += 1\n",
    "        env.reset()\n",
    "        epsilon = epsilon_min + (epsilon_max-epsilon_min)*np.exp(-i/epsilon_decay)\n",
    "        it_counter = 0\n",
    "        reward = 0\n",
    "        while(not(env.done) and it_counter < max_episode_duration):\n",
    "            it_counter += 1\n",
    "            # Chose an action\n",
    "            if (rd.random() <= epsilon):\n",
    "                action = env.random_action()\n",
    "            else:\n",
    "                with torch.no_grad() :\n",
    "                    action = env.policy()\n",
    "\n",
    "            # Apply the transition and save it in memory\n",
    "            transition = env.step(action)\n",
    "            reward += (transition.reward).item()\n",
    "            env.memory.push(transition)\n",
    "            # Optimize by observing batch_size random transitions\n",
    "            optimize(env,optimizer,criterion,batch_size,discount_factor)\n",
    "        # Stats about the training\n",
    "        second = (int(time.perf_counter() - time_start)) % 60\n",
    "        minute = (int(time.perf_counter() - time_start)) //60\n",
    "        if (minute%5 == 0 and minute > 3) :\n",
    "            env.model.save(filename)\n",
    "\n",
    "        #if ( second <= 3  ) :\n",
    "                #env.show_state()\n",
    "        normalizer = 1\n",
    "        window_len = 30\n",
    "        iteration_time = time.perf_counter() - time_start\n",
    "        reward_history.append(reward*normalizer)\n",
    "        reward_time.append( iteration_time  )\n",
    "        last_window = reward_history[-window_len:]\n",
    "        volatility_history.append(np.std(last_window))\n",
    "        volatility_time.append(iteration_time)\n",
    "        \n",
    "\n",
    "    res = {}\n",
    "    res[\"training_time\"] = time_bound\n",
    "    res[\"track_number\"] = len(TRACKS)\n",
    "    res[\"global_volatility\"] = np.std(reward_history)\n",
    "    res[\"model_size\"] = measure_model_size(env)\n",
    "    res[\"policy_time\"] = measure_policy_time(env)\n",
    "    res[\"policy_score\"] = evaluate_model_reward(env)\n",
    "    res[\"reward_history\"] = reward_history\n",
    "    res[\"reward_time\"] = reward_time \n",
    "    res[\"volatility_history\"] = volatility_history\n",
    "    res[\"volatility_time\"] = volatility_time \n",
    "    res[\"DQN_model_param\"] = filename\n",
    "    res[\"DQN_model_param_is_saved\"] = False\n",
    "\n",
    "    res[\"learning rate\"] = lr \n",
    "    res[\"batch size\"] = batch_size\n",
    "    res[\"epsilon decay\"] = epsilon_decay\n",
    "\n",
    "    minute = (int(time.perf_counter() - time_start)) //60\n",
    "    if (minute > 3) :\n",
    "         env.model.save(filename)\n",
    "         res[\"DQN_model_param_is_saved\"] = True\n",
    "\n",
    "    # plt.plot(reward_history)\n",
    "    # plt.plot(volatility_history)\n",
    "    # plt.show()\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#res = training(time_bound=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def par1_data():\n",
    "    #training_times_min = [10,30,60]\n",
    "    training_times_min = [10,40,60]\n",
    "    training_times_sec = [60*i for i in training_times_min]\n",
    "    track_limit = [8,40, int(0.8*len(TRACKS)) ]\n",
    "    #track_limit = [10]\n",
    "    if (len(TRACKS) < max(track_limit)) :\n",
    "        raise(ValueError(\"not enough tracks\"))\n",
    "    folder_name =  \"run_part1_\"+ datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "    os.makedirs(folder_name)\n",
    "    for t in training_times_sec :\n",
    "        for n_track in track_limit :\n",
    "            json_object = json.dumps( training(time_bound=t,track_budget=n_track))\n",
    "            with open(folder_name + \"/\" + str(t)+\"_\"+str(n_track)+\".json\",\"w\") as f :\n",
    "                f.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def par2_data():\n",
    "    #training_times_min = [10,30,60]\n",
    "    training_time = 30*(60)\n",
    "    lr_l = [1e-2,1e-3,1e-4,1e-5,1e-6]\n",
    "    batch_size_l = [10,30,50,80,120]\n",
    "    epsilon_decay_l = [10.,30.,50.,120.,200.]\n",
    "    track_limit = int(0.8*len(TRACKS))\n",
    "\n",
    "    folder_name =  \"run_part2_\"+ datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "    for par in lr_l :\n",
    "        json_object = json.dumps( training(lr=par, track_budget=track_limit , time_bound=training_time ))\n",
    "        with open(folder_name + \"/\" + \"lr\"+\"_\"+str(par)+\".json\",\"w\") as f :\n",
    "            f.write(json_object)\n",
    "\n",
    "    for par in batch_size_l :\n",
    "        json_object = json.dumps( training(batch_size=par, track_budget=track_limit , time_bound=training_time ))\n",
    "        with open(folder_name + \"/\" + \"batch_size\"+\"_\"+str(par)+\".json\",\"w\") as f :\n",
    "            f.write(json_object)\n",
    "\n",
    "    for par in epsilon_decay_l :\n",
    "        json_object = json.dumps( training(epsilon_decay=par, track_budget=track_limit , time_bound=training_time ))\n",
    "        with open(folder_name + \"/\" + \"epsilon_decay\"+\"_\"+str(par)+\".json\",\"w\") as f :\n",
    "            f.write(json_object)\n",
    "\n",
    "    # for t in training_times_sec :\n",
    "    #     for n_track in track_limit :\n",
    "    #         json_object = json.dumps( training(time_bound=t,track_budget=n_track))\n",
    "    #         with open(folder_name + \"/\" + str(t)+\"_\"+str(n_track)+\".json\",\"w\") as f :\n",
    "    #             f.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def par3_data():\n",
    "    #training_times_min = [10,30,60]\n",
    "    training_times = (60)*(60)*6\n",
    "    track_limit = int(0.8*len(TRACKS))\n",
    "    #track_limit = [10]\n",
    "    folder_name =  \"run_part3_\"+ datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "    os.makedirs(folder_name)\n",
    "    json_object = json.dumps( training(time_bound=training_times,track_budget=track_limit, lr=1e-5 , epsilon_decay=500.))\n",
    "    with open(folder_name + \"/\" + \"long training\"+\".json\",\"w\") as f :\n",
    "        f.write(json_object)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#par2_data() \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#par1_data()\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mpar3_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[46], line 8\u001b[0m, in \u001b[0;36mpar3_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m folder_name \u001b[38;5;241m=\u001b[39m  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_part3_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(folder_name)\n\u001b[0;32m----> 8\u001b[0m json_object \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mdumps( \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_bound\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_times\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrack_budget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrack_limit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-5\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500.\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(folder_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlong training\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f :\n\u001b[1;32m     10\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(json_object)\n",
      "Cell \u001b[0;32mIn[35], line 48\u001b[0m, in \u001b[0;36mtraining\u001b[0;34m(lr, epsilon_decay, batch_size, time_bound, track_budget)\u001b[0m\n\u001b[1;32m     45\u001b[0m         action \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mpolicy()\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Apply the transition and save it in memory\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m transition \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (transition\u001b[38;5;241m.\u001b[39mreward)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     50\u001b[0m env\u001b[38;5;241m.\u001b[39mmemory\u001b[38;5;241m.\u001b[39mpush(transition)\n",
      "Cell \u001b[0;32mIn[19], line 63\u001b[0m, in \u001b[0;36mEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mabsolute(turn) \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mmax_turn:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28mprint\u001b[39m(action\u001b[38;5;241m.\u001b[39mitem(), (acc, turn))\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate_gym,reward,terminated,truncated,_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n\u001b[1;32m     66\u001b[0m next_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate()\n",
      "Cell \u001b[0;32mIn[9], line 115\u001b[0m, in \u001b[0;36mRacingCar.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid_line_goal \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid_line_goal \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrack\u001b[38;5;241m.\u001b[39mlines))\n\u001b[1;32m    114\u001b[0m reward \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 115\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, reward, is_done, has_crashed, []\n",
      "Cell \u001b[0;32mIn[9], line 47\u001b[0m, in \u001b[0;36mRacingCar.get_state\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     45\u001b[0m state \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcar\u001b[38;5;241m.\u001b[39mspeed]\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m alpha \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mliste_alpha:\n\u001b[0;32m---> 47\u001b[0m     coor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_wall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdist_max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_dist_wall\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     state\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcar\u001b[38;5;241m.\u001b[39mcoor\u001b[38;5;241m.\u001b[39mdist(coor))\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m state\n",
      "Cell \u001b[0;32mIn[5], line 177\u001b[0m, in \u001b[0;36mTrack.next_wall\u001b[0;34m(self, coor, alpha, dist_max)\u001b[0m\n\u001b[1;32m    175\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    176\u001b[0m next_coor \u001b[38;5;241m=\u001b[39m Coor( (\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mround\u001b[39m(coor\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m+\u001b[39m i\u001b[38;5;241m*\u001b[39mdx)), \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mround\u001b[39m(coor\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m+\u001b[39m i\u001b[38;5;241m*\u001b[39mdy))) )\n\u001b[0;32m--> 177\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_case_ridable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_coor\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (dist_max\u001b[38;5;241m!=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (coor\u001b[38;5;241m.\u001b[39mdist(next_coor) \u001b[38;5;241m>\u001b[39m dist_max):\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 132\u001b[0m, in \u001b[0;36mTrack.is_case_ridable\u001b[0;34m(self, coor)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (x\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m x\u001b[38;5;241m<\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;129;01mand\u001b[39;00m y\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m y\u001b[38;5;241m<\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight):\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_wall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoor\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 113\u001b[0m, in \u001b[0;36mTrack.is_wall\u001b[0;34m(self, coor)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return True if case (x,y) is a wall\"\"\"\u001b[39;00m\n\u001b[1;32m    112\u001b[0m x,y \u001b[38;5;241m=\u001b[39m coor\u001b[38;5;241m.\u001b[39mget()\n\u001b[0;32m--> 113\u001b[0m nx,ny \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mround\u001b[39m(x)), \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28;43mround\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo_track[nx][ny] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "par2_data() \n",
    "#par1_data()\n",
    "#par3_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#par1_data()\n",
    "\n",
    "# for key, value in res.items() :\n",
    "#     print(key,\" \",value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder_name =  \"run_part1_\"+ datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "# os.makedirs(folder_name)\n",
    "# json_object = json.dumps( res)\n",
    "# with open(folder_name+\"/\" + \"test.json\",\"w\") as f :\n",
    "#             f.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"run_part1_2024-12-03_20:50:34/360_10.json\") as f :\n",
    "#     dic = json.load(f)\n",
    "# print(dic)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def playing(env):\n",
    "    sum = 0\n",
    "    max_step = 300\n",
    "    for i in range(70,len(TRACKS)) :\n",
    "        env.state_gym , _ = env.env.reset(TRACKS[i])\n",
    "        env.done = False\n",
    "        i = 0\n",
    "        while(i < max_step and not(env.done)) :\n",
    "            i+=1\n",
    "            transition = env.step( env.policy() )\n",
    "            sum += transition.reward.item()\n",
    "            env.show_state()\n",
    "    return sum/( len(TRACKS) - 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = Env()\n",
    "# env.track_for_training = len(TRACKS)\n",
    "# with open(\"run_part1_2024-12-03_23:09:23/3600_69.json\") as f :\n",
    "#     dic = json.load(f)\n",
    "# env.model.load(dic[\"DQN_model_param\"])\n",
    "# # playing(env)\n",
    "# plt.plot(dic[\"reward_history\"])\n",
    "# print(dic[\"global_volatility\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
