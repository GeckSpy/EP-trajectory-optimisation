% Packages
\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{hyperref}
\usepackage{lmodern}
\usepackage[english]{babel}
\usepackage{appendix}
\usepackage{enumitem}

%Fusionneer des pages
\usepackage{pgfpages}
%\pgfpagesuselayout{4 on 1}[a4paper,border shrink=5mm]

% Taille marges
\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}
% Titles size
\usepackage[small]{titlesec}

% math
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathabx}
\usepackage{stmaryrd}

\usepackage[most]{tcolorbox}
\newtcolorbox[auto counter]{definition}[1]{colframe=red!75!black, coltitle=white, enhanced, frame empty, colback=white,fonttitle=\bfseries , title=Def \thetcbcounter$\;$: #1, borderline west={2pt}{0pt}{red!85!black},
attach boxed title to top left={xshift=-5mm}, boxed title style={colback=red!75!black}}

\newtcolorbox[auto counter]{prop}{colframe=black!80!white, coltitle=black, enhanced, frame empty, colback=white,fonttitle=\bfseries , title=\underline{Property \thetcbcounter$\;$:}, borderline west={2pt}{0pt}{black},
attach boxed title to top left={xshift=-4mm}, boxed title style={frame empty,colback=white}}

\newtcolorbox[auto counter]{thm}[1]{colframe=blue!70!black,colback=white,fonttitle=\bfseries , title=Theorem \thetcbcounter$\;$: #1}

\newtcolorbox[auto counter]{exercice}{colframe=white,colback=white,fonttitle=\bfseries , title=Exercice \thetcbcounter$\;$:}

\newtcolorbox{preuve}{boxrule=0pt, enhanced, colback=white, colframe=white, coltitle=black, fonttitle=\bfseries , title=\underline{Proof $\;$:},
top=0mm, frame empty, borderline west={1pt}{0pt}{black}, sharp corners,
after upper={\par\hfill\textit{$\blacksquare $}}}

\newtcolorbox{mybox}{colframe=white!75!black,colback=white!95!black,fonttitle=\bfseries}

% pseudo code
\usepackage[ruled,lined,noend]{algorithm2e}
\usepackage{babel}

% insertion image
\usepackage{graphicx}
\graphicspath{ {./images/} }

% derivation tree
\usepackage{ebproof}

% automate
\usepackage{caption}
\usepackage{tikz}
\usetikzlibrary{automata, positioning, arrows, decorations.pathreplacing, decorations.markings, positioning, shapes, quotes}


\newcounter{fig}
\newcommand{\fig}[3]{
	\begin{center}
	\begin{figure}[ht]
		\refstepcounter{fig}
		\centering
		\begin{tikzpicture}[scale=#3]
		#1
		\end{tikzpicture}
		\caption{\underline{#2}}
	\end{figure}
	\end{center}
}

\newcommand{\tab}{\phantom{xxx}}

\newcommand{\ignore}[1]{}

\newcommand{\uao}[3]{\underset{#1}{\overset{#2}{#3}}}

\renewcommand{\lim}[2]{\underset{#1 \rightarrow #2}{lim}}

\newcommand{\mlist}[1]{\begin{itemize}[noitemsep,topsep=0pt]#1\end{itemize}}



\title{\vspace{-1.0cm}Performance Evaluation project:\\\underline{Optimizing cars' trajectory with AI}}
\date{}
\author{\vspace{-1cm}Ottavy Mac√©o, Longatte Mathieu, Louison Mocq}

\begin{document}
\maketitle
%\tableofcontents

	\part{Introduction}
The goal of this project is split into five parts:
\mlist{
\item Creating racing car environment to simulate simple 2D racing car model.
\item Implementing Deep Q-learning and Genetic algorithms to optmize the behaviour of a car on trakcs so that the car can have the best trajectories possible.
\item Evalute the performances of Deep Q-learning and Genetic algorithms and compare them.
\item Evalute the performances of Deep Q-learning depending of the hyperparameters.
\item As a bonus: evaluate the performance of our best car's behaviour.
}
All the code have been made with python.

	\part{Deep Q-learning}
		\section{Markovian decision porcess}
		
		\section{What is Q value?}
		
		\section{What is Q learning}

	
	\part{Genetic algorithms}
		\section{What are genetic algorithms}
		
		\section{Markov Chain modelisation}
		
		\section{NEAT}
	
	
	\part{Car Racing environment}
		\section{Tracks}
A track is originally a .png file wich look like the left image of figure \ref{figure:track}. Then, the image is converted to a matrix $T$ such that $T[0][0]$ is the bottom left corner. After that, we crop the image, compute the starting point and the lines of track (that will be explained in the reward part) to have a final result which look the right image of figure \ref{figure:track}.
\begin{center}
\label{figure:track}
	\begin{figure}[ht]
		\refstepcounter{fig}
		\centering
		\includegraphics[width=5cm, height=4cm]{track_06.png}
		\includegraphics[width=5cm, height=4cm]{track_06_computed.png}
		\caption{\underline{.png and computed track}}
	\end{figure}
\end{center}

	
		\section{Cars' physics}
The Car physic is really simple. It is a 2D cartoon-like physics that act as follow:\\
The car has to main informations: its speed $\in [0,$ MaxSpeed$]$ and its rotation $\in [0,360]$. The physics is simple, at each times step, the car move to next coordinates on direction of the car's rotation and of a lenght equal to the car's speed.\\
If the coordinates of the car is $(x,y)$, its speed is $s$ and its rotation is $\alpha$, then, after a time step, the coordinate of the car will be:
\[(s.cos(\frac{\pi}{180}\alpha) + x,\; s.sin(\frac{\pi}{180}\alpha) + x)\]
\\
Moreover, at each time step, the car can make some actions:
\mlist{
\item it can accelerate, this will increase the car's speed by a constant
\item it can brake, this will decrease the car's speed by reduce the car speed by a constant. The car cannot have a negative speed.
\item it can turn, i.e. add a constant $\in \llbracket-K,K\rrbracket$ to its rotation. $K$ is a constant that is the maximum angle the car can turn per each time step.
}
The behaviour of the car will need to interact with the track therefore we need to decide what is the state of a car, i.e. how the car see the environment. We could give to our algorithms the track matrices, the informations of the car but this will leed to to many argument because a track can have size $900\times600$. Therefore we will need to train on all possible state wich will be at least $2^{900\times 600}$. Therefore, we decided to give a more realistic state wich represent how a car racer see. Then the state of a car is a array of size $8$.
\mlist{
\item $T_0$ is the current speed of the car
\item $\forall i\in\{1,...,7\}$, $T_i$ is the distance of the car to the next wall in the direction $\alpha + A_{i-1}$ where $\alpha$ is the current rotation of the car and $A=[60, 40, 20, 0, -20, -40, -60]$
}
Then, the representation looks like figure \ref{figure:car state}.
\begin{center}
\label{figure:car state}
	\begin{figure}[ht]
		\refstepcounter{fig}
		\centering
		\includegraphics[width=5cm, height=4cm]{car_state.png}
		\caption{\underline{Car state}}
	\end{figure}
\end{center}
		
		\section{Technical aspects of the environment}
To manipulate our environment, we use the python packages \texttt{gymnasium} which provide code convention for those type or environment, i.e. environment where at each time step, you have one action to do. The environment has to have some essential function: \texttt{reset()} that reset the environment to be able to do an other simulation, \texttt{render()} that render the current state of our environment and the most important one is \texttt{step()} that do one step of time, i.e. given an action, the \texttt{step()} function figure out is the car has crashed or not, move the carn to its next position and return the new state of the car, a reward and if the car has crashed.\\
Our environment has a variable named \texttt{time} wich give us the opportunitie to discretise more or less or time.
		
		\section{Rewards}
For those type of problem where the AI model has to compute a behaviour, the AI model produces something which look like a function $f$ that take a car state and return an action. We need to specifie to our AI model when it produce a good action and a bad action, for instance, if a car crash, we need to punish the AI model.\\
We do that thanks to a function reward implemented in the function \texttt{step()} of our environment. The reward is an integer, the bigger it is the best the action was. To punished the car when it do something bad we do:
\mlist{
\item If the car crashes, we stop the simulation and return a reward of $-500$
\item If the car is not moving, i.e. has a speed of $0$, the reward is $-10$
}
For the positive reward, we have automatically computed some track line (represented in right image of figure \ref{figure:track}). If the car crosses next line, it has a reward of $+10\times$ the number of lines it has cross in the good order with this action. If the car cross a line in the wrong order, it means that it has gone backward, therefore, we punished the car with a reward of $-200$ and we stop the computation.\\
On top of that, at each time step, we add to the current reward the speed of the car divided by a constant to encourage the car to go fast.
	
	
	\part{Performance Evaluation}
		\section{Algorithms}
		
		\section{Best car}



\end{document}